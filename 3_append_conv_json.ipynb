{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHES_FOLDER = r'C:/Users/nanadhirah/Desktop/important/legislation/batches_csv'\n",
    "OUTPUT_CSV_FILE = 'final_output_legislation.csv'\n",
    "JSON_FILE = 'final_output_legislation.json'\n",
    "COMBINED_CSV_FILE = 'combined_batches_legislation.csv'\n",
    "LINK_CSV_FILE = 'pdf_legislation_links.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_batches_to_csv(BATCHES_FOLDER, combined_csv_file): \n",
    "    \"\"\"\n",
    "    Combine all batch CSV files into a single CSV file, removing duplicate records.\n",
    "\n",
    "    Args:\n",
    "        BATCHES_FOLDER (str): Folder containing all batch CSV files.\n",
    "        combined_csv_file (str): Path to save the combined CSV file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the combined CSV file.\n",
    "    \"\"\"\n",
    "    # Locate all batch CSV files\n",
    "    batch_files = [os.path.join(BATCHES_FOLDER, file) for file in os.listdir(BATCHES_FOLDER) if file.endswith('.csv')]\n",
    "    if not batch_files:\n",
    "        raise FileNotFoundError(\"No batch files found in the specified folder.\")\n",
    "    \n",
    "    print(f\"Found {len(batch_files)} batch files in {BATCHES_FOLDER}. Combining...\")\n",
    "    \n",
    "    # Num of records existed in combined_df csv\n",
    "    existing_combined_df = pd.read_csv(combined_csv_file)\n",
    "    num_existing_records = len(existing_combined_df)\n",
    "    print(f\"Number of records in the existing combined CSV: {num_existing_records}\")\n",
    "\n",
    "    # Combine all batch files into a single DataFrame\n",
    "    combined_df = pd.concat((pd.read_csv(file) for file in batch_files), ignore_index=True)\n",
    "    print(\"Number of records with duplication:\" , len(combined_df))\n",
    "    \n",
    "    # Drop duplicate rows based on all columns\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    print(\"Number of records after deduplication:\",len(combined_df))\n",
    "    \n",
    "    # Save the combined data as a CSV after deduplication\n",
    "    combined_df.to_csv(combined_csv_file, index=False)\n",
    "    print(f\"Combined CSV saved to: {combined_csv_file}\")\n",
    "    \n",
    "    return combined_csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_process_csv(pdf_links_csv, combined_csv, output_csv):\n",
    "    \"\"\"\n",
    "    This function merges two CSV files based on the 'PDF File' column,\n",
    "    processes the merged data, and saves the result to a new CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_links_csv (str): Path to the first CSV file containing PDF links.\n",
    "    - combined_csv (str): Path to the second CSV file to be merged.\n",
    "    - output_csv (str): Path where the merged and processed CSV should be saved.\n",
    "    \"\"\"\n",
    "    # Read the CSV files into DataFrames\n",
    "    pdf_links_df = pd.read_csv(pdf_links_csv)\n",
    "    combined_df = pd.read_csv(combined_csv)\n",
    "\n",
    "    # Merge the DataFrames on 'PDF File' column\n",
    "    merged_df = pd.merge(pdf_links_df, combined_df, on='PDF File')\n",
    "\n",
    "    # Perform further operations on the merged DataFrame\n",
    "    merged_df['URL'] = merged_df['Original Link'].apply(lambda x: urlparse(x).netloc)\n",
    "    merged_df = merged_df[['URL', 'Original Link', 'Document_Text', 'Text_Len', 'Text_Ext_Method']]\n",
    "    merged_df.rename(columns={'Original Link': 'Document'}, inplace=True)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Processed data saved to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_json(csv_file, json_file):\n",
    "    \"\"\"\n",
    "    Converts a CSV file to JSON format and saves it to a specified location.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file (str): Path to the CSV file to be converted.\n",
    "    - json_file (str): Path where the JSON file should be saved.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert the DataFrame to JSON and save it\n",
    "    df.to_json(json_file, orient='records', lines=True)\n",
    "\n",
    "    print(f\"CSV data has been successfully converted to JSON and saved as: {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1455 batch files in C:/Users/nanadhirah/Desktop/important/legislation/batches_csv. Combining...\n",
      "Number of records in the existing combined CSV: 10180\n",
      "Number of records with duplication: 14545\n",
      "Number of records after deduplication: 14545\n",
      "Combined CSV saved to: combined_batches_legislation.csv\n",
      "Processed data saved to: final_output_legislation.csv\n",
      "CSV data has been successfully converted to JSON and saved as: final_output_legislation.json\n"
     ]
    }
   ],
   "source": [
    "# Combine batch CSV files into one\n",
    "combined_csv_path = combine_batches_to_csv(BATCHES_FOLDER, COMBINED_CSV_FILE)\n",
    "\n",
    "merge_and_process_csv(LINK_CSV_FILE, COMBINED_CSV_FILE, OUTPUT_CSV_FILE)\n",
    "\n",
    "# Convert the final CSV to JSON in the same directory\n",
    "#final_json_file = 'try_final_legislation.json'  # Just the file name\n",
    "convert_csv_to_json(OUTPUT_CSV_FILE, JSON_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
